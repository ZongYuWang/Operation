## 视频编码协议

### 1、HLS协议
#### 1.1 什么是HLS协议：
&emsp;&emsp;简单讲就是把整个流分成一个个小的，基于HTTP的文件来下载，每次只下载一些，基于H5播放直播视频时引入的一个.m3u8的文件，这个文件就是基于HLS协议，存放视频流元数据的文件
&emsp;&emsp;每一个 .m3u8 文件，分别对应若干个ts文件，这些ts文件才是真正存放视频的数据，m3u8文件只是存放了一些ts文件的配置信息和相关路径，当视频播放时，.m3u8是动态改变的，video标签会解析这个文件，并找到对应的ts 文件来播放，所以一般为了加快速度，.m3u8放在web服务器上，ts文件放在CDN上
&emsp;&emsp;.m3u8文件，其实就是以UTF-8编码的m3u文件，这个文件本身不能播放，只是存放了播放信息的文本文件：
```ruby
#EXTM3U                 m3u文件头
#EXT-X-MEDIA-SEQUENCE   第一个TS分片的序列号
#EXT-X-TARGETDURATION   每个分片TS的最大的时长
#EXT-X-ALLOW-CACHE      是否允许cache
#EXT-X-ENDLIST          m3u8文件结束符
#EXTINF                 指定每个媒体段(ts)的持续时间（秒），仅对其后面的URI有效
mystream-12.ts
```
![](https://github.com/ZongYuWang/image/blob/master/%E6%B5%81%E5%AA%92%E4%BD%93/HLS1.png)


video 标签播放 hls 协议视频：
```ruby
 <video controls autoplay>  
     <source src="http://10.66.69.77:8080/hls/mystream.m3u8" type="application/vnd.apple.mpegurl" />  
     <p class="warning">Your browser does not support HTML5 video.</p>  
 </video> 
```
#### 1.2 HLS直播延时
&emsp;&emsp;HLS协议是将直播流分成一段一段的小段视频去下载播放的，所以假设列表里面的包含5个ts文件，每个TS文件包含5秒的视频内容，那么整体的延迟就是25秒。因为当你看到这些视频时，主播已经将视频录制好上传上去了，所以时这样产生的延迟。当然可以缩短列表的长度和单个ts文件的大小来降低延迟，极致来说可以缩减列表长度为1，并且ts的时长为1s，但是这样会造成请求次数增加，增大服务器压力，当网速慢时回造成更多的缓冲，所以苹果官方推荐的ts时长时10s，所以这样就会大改有30s的延迟
#### 1.3 视频采集
&emsp;&emsp;**视频编码**：所谓视频编码就是指通过特定的压缩技术，将某个视频格式的文件转换成另一种视频格式文件的方式，我们使用的iphone录制的视频，必须要经过编码，上传，解码，才能真正的在用户端的播放器里播放
&emsp;&emsp;**编解码标准**：视频流传输中最为重要的编解码标准有国际电联的H.261、H.263、H.264，其中HLS协议支持H.264格式的编码。
&emsp;&emsp;**音频编码**：同视频编码类似，将原始的音频流按照一定的标准进行编码，上传，解码，同时在播放器里播放，当然音频也有许多编码标准，例如PCM编码，WMA编码，AAC编码等等，HLS协议支持的音频编码方式是AAC编码

![](https://github.com/ZongYuWang/image/blob/master/%E6%B5%81%E5%AA%92%E4%BD%93/HLS2.png)

### 2、RTMP协议
&emsp;&emsp;RTMP（Real Time Messaging Protocol）是Macromedia开发的一套视频直播协议，现在属于 Adobe。和HLS一样都可以应用于视频直播，区别是RTMP基于flash无法在ios的浏览器里播放，但是实时性比HLS要好。所以一般使用这种协议来上传视频流，也就是视频流推送到服务器


| - | 协议 | 原理 | 延时 | 优点 | 使用场景 | 
| - | - | - | - | - | - | 
| RTMP |长链接TCP| 每个时刻的数据收到后立刻发送 | 2S | 延时低 | 即时互动| 
| HLS | 短链接HTTP | 集合一段时间数据生成ts切片文件更新m3u8文件 | 10s-30s | 跨平台 | H5直播

### 3、推流服务器
#### 3.1 推流：
&emsp;&emsp;推流是将我们已经编码好的音视频数据发往视频流服务器中，一般常用的是使用RTMP 推流，可以使用第三方库librtmp-iOS 进行推流，librtmp封装了一些核心的api供使用者调用
#### 3.2 推流服务器搭建：
- 安装一台Nginx服务器
- 安装Nginx的RTMP扩展
- 配置Nginx的conf文件

```ruby
rtmp {  

     server {  

         listen 1935;  #监听的端口

         chunk_size 4000;  


         application hls {  #rtmp推流请求路径
             live on;  
             hls on;  
             hls_path /usr/local/var/www/hls;  
             hls_fragment 5s;  
         }  
     }  
 }  

// 重启nginx，将rtmp的推流地址写为 rtmp://ip:1935/hls/mystream
// hls_path 表示生成的.m3u8 和ts文件所存放的地址
// hls_fragment 表示切片时长
// mysteam 表示一个实例，即将来要生成的文件名可以先自己随便设置一个
```
```ruby
./configure --add-module=/path/to/nginx-rtmp-module --with-http_ssl_module
make
make install
```

### 4、RTSP协议
&emsp;&emsp;RTSP协议是一个流媒体协议，可以实现直播和点播形式的音频与视频流的播放。RTSP协议定义了多种服务器-客户端之间交互的接口，主要有OPTIONS，DESCRIBE，SETUP，PLAY，TEARDOWN，RECORD，ANNOUNCE。       
&emsp;&emsp;RTSP并不包括具体数据的传输，该功能一般由RTP与RTCP协议来实现，并可以通过TCP或UDP两种底层传输方式进行。          
&emsp;&emsp;RTSP直播过程中服务端-客户端主要交互过程如下：        
![](https://github.com/ZongYuWang/image/blob/master/%E6%B5%81%E5%AA%92%E4%BD%93/RTSP1.png)      

&emsp;&emsp;绿色部分表示的是数据传输，流媒体数据传输不是RTSP协议的内容，由RTP包来做。但是具体在实现上，RTP包可以通过UDP或TCP的方式来进行，而且这两种传输方式，有很大的区别


#### 4.1 RTSP over UDP：
&emsp;&emsp;对于udp模式，客户端在发送PLAY以后，就开始建立udp端口，以接收服务器发来的RTP包，同样，服务器也会建立udp端口，并向客户端发送RTP包。这是网上大部分程序所采用的方式，优点是逻辑清晰，实现方便，不过缺点也很明显，就是udp所固有的，容易丢包，尤其是在高分辨率高码率下       
![](https://github.com/ZongYuWang/image/blob/master/%E6%B5%81%E5%AA%92%E4%BD%93/RTSP2.png)

#### 4.2 RTSP over TCP：
&emsp;&emsp;对tcp模式，通过SETUP接口来指定传输方式，服务器返回同样数据以确定双方通过tcp方式来传输数据。不过跟udp最大的不同是，rtsp over tcp的形式，不再创建单独的tcp通道，而是直接使用之前rtsp通信所使用的tcp通道，流程如下所示：      
![](https://github.com/ZongYuWang/image/blob/master/%E6%B5%81%E5%AA%92%E4%BD%93/RTSP3.png)